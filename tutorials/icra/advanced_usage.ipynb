{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "85dac984-8ab6-4d17-907d-d352b8a896e9",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Notebook Setup\n",
    "\n",
    "In order to be able to run the code, we need to install the *eagerx_tutorials* package and ROS.\n",
    "\n",
    "### Activate GPU (**Colab only**)\n",
    "\n",
    "When in Colab, you'll need to enable GPUs for the notebook:\n",
    "\n",
    "- Navigate to Editâ†’Notebook Settings\n",
    "- select GPU from the Hardware Accelerator drop-down"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40a146a4-2e29-44e7-adac-797173b1b012",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not running on CoLab.\n",
      "Execute ROS commands as \"!...\".\n",
      "ROS melodic available.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    import eagerx_tutorials\n",
    "except ImportError:\n",
    "    !{\"echo 'Installing eagerx-tutorials with pip.' && pip install eagerx-tutorials >> /tmp/eagerx_install.txt 2>&1\"}\n",
    "if 'google.colab' in str(get_ipython()):\n",
    "    !{\"curl 'https://raw.githubusercontent.com/eager-dev/eagerx_tutorials/master/scripts/setup_colab.sh' > ~/setup_colab.sh\"}\n",
    "    !{\"bash ~/setup_colab.sh\"}\n",
    "\n",
    "# Setup interactive notebook\n",
    "# Required in interactive notebooks only.\n",
    "from eagerx_tutorials import helper\n",
    "helper.setup_notebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "655b07b3-26ca-4bb8-87b7-e61837e61136",
   "metadata": {},
   "source": [
    "# EAGERx Advanced usage - ICRA 2022\n",
    "\n",
    "Github repo: https://github.com/araffin/tools-for-robotic-rl-icra2022\n",
    "\n",
    "EAGERx: https://github.com/eager-dev/eagerx\n",
    "\n",
    "Documentation: https://eagerx.readthedocs.io/en/master/\n",
    "\n",
    "\n",
    "## Introduction\n",
    "\n",
    "In this notebook, you will learn to use eagerx to create a gym-compatible environment. This tutorial covers:\n",
    "- how to initialize a robot (Go 1 Quadruped Robot).\n",
    "- how to add pre-processing nodes (i.e. low-level controllers).\n",
    "- how to fine-tune low-level controllres to achieve the desired behavior.\n",
    "- how to (de)select various sensors to investigate its effect on the learning performance.\n",
    "\n",
    "In the remainder of this tutorial, we will go more into detail on these concepts.\n",
    "\n",
    "Furthermore, you will be asked to add/modify a couple of lines of code, which are marked by\n",
    "\n",
    "```python\n",
    "\n",
    "# YOUR CODE HERE\n",
    "\n",
    "# END OF YOUR CODE\n",
    "```\n",
    "\n",
    "## Quadruped Locomotion\n",
    "\n",
    "In this tutorial, we will learn small offsets to the trot of a [Go 1 Quadruped](https://tribotix.com/product/go1-quadruped-robot/) so that the quadruped makes a left-turn instead of going straight ahead. For this, we will start with an open-loop trot gait that uses a central pattern generator ([CPG](https://en.wikipedia.org/wiki/Central_pattern_generator#Locomotion)) to walk straight ahead. Central pattern generators have been used to control the motion of individual joints of walking robots and in this tutorial we will use one that is based on the Hopf oscillator.\n",
    "\n",
    "In a nutshell, we will use a Hopf network to produce desired cartesian coordinates for the quadruped's feet. Then, the cartesian coordinates are mapped to desired joint positions using the forward kinematics of the quadruped. The desired joint positions are then tracked using the quadruped's joint controllers.\n",
    "\n",
    "## Let's get started\n",
    "\n",
    "First we will import EAGERx and initialize it.\n",
    "EAGERx makes use of ROS functionality for communication and during initialization a ROS master is started if there isn't one running already."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e187238-9d0d-404b-9888-9f60bcdb8dc6",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... logging to /home/bas/.ros/log/5a5a9c74-d95e-11ec-9269-02421573ea46/roslaunch-bas-Alienware-m15-R2-24810.log\n",
      "\u001b[1mstarted roslaunch server http://172.18.0.1:46771/\u001b[0m\n",
      "ros_comm version 1.14.11\n",
      "\n",
      "\n",
      "SUMMARY\n",
      "========\n",
      "\n",
      "PARAMETERS\n",
      " * /rosdistro: melodic\n",
      " * /rosversion: 1.14.11\n",
      "\n",
      "NODES\n",
      "\n",
      "auto-starting new master\n",
      "\u001b[1mprocess[master]: started with pid [24863]\u001b[0m\n",
      "\u001b[1mROS_MASTER_URI=http://localhost:11311\u001b[0m\n",
      "\u001b[1msetting /run_id to 5a5a9c74-d95e-11ec-9269-02421573ea46\u001b[0m\n",
      "\u001b[1mprocess[rosout-1]: started with pid [24885]\u001b[0m\n",
      "started core service [/rosout]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<roslaunch.parent.ROSLaunchParent at 0x7f322700ea60>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import eagerx\n",
    "# Initialize eagerx (starts roscore if not already started.)\n",
    "eagerx.initialize(\"eagerx_core\", log_level=eagerx.log.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2e28b59-a12c-43b7-a74e-caac8e2019fb",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Graph definition\n",
    "Next, we initialize a [Go 1 Quadruped](https://tribotix.com/product/go1-quadruped-robot/) that we prepared for this tutorial.\n",
    "\n",
    "It has various sensors available that run at 20 Hz:\n",
    "- `joint_position`: the position of the quadruped's leg joints in radians, so 4 legs with 2 joints each.\n",
    "- `joint_velocity`: the angular velocity in radians of the quadruped's leg joints.\n",
    "- `force_torque`: The joint reaction forces of the quadruped's leg joints (Fx, Fy, Fz, Mx, My, Mz).\n",
    "- `orientation`: the orientation of the quadruped's body in quaternions (x, y, z, w).\n",
    "- `position`: the global cartesian position of the quadruped's body in meter (x, y, z).\n",
    "- `velocity`: the global cartesian velocity of the quadruped's body in meters per second (dx, dy, dz).\n",
    "\n",
    "and an actuator that runs at 200 Hz:\n",
    "- `joint_control`: Tracks the desired joint positions of the quadruped's leg joints in radians."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "85258bb6-927f-4ae0-869f-f88decaacc56",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pybullet build time: Apr 26 2022 03:12:14\n"
     ]
    }
   ],
   "source": [
    "# Available sensors\n",
    "sensors = [\"joint_position\", \"joint_velocity\", \"force_torque\", \"orientation\", \"position\", \"velocity\"]\n",
    "actuators = [\"joint_control\"]\n",
    "\n",
    "# Create the GO 1 quadruped\n",
    "import eagerx_tutorials.quadruped.object\n",
    "robot = eagerx.Object.make(\"Quadruped\", \"quadruped\", actuators=actuators, sensors=sensors, rate=20)\n",
    "\n",
    "# Set the quadruped's control rate to 200 Hz.\n",
    "robot.actuators.joint_control.rate = 200"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13d5c0d2-e12c-451d-8848-b9c53c04c1ff",
   "metadata": {},
   "source": [
    "Then, we initialize the central pattern generator and cartesian control nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d2f1761b-9640-4f04-aa1f-a0da16694c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create central pattern generator (uses Hopf Oscillator)\n",
    "import eagerx_tutorials.quadruped.cpg_gait\n",
    "cpg = eagerx.Node.make(\"CpgGait\", \"cpg\", rate=200, gait=\"TROT\", omega_swing=16 * 3.14, omega_stance=4 * 3.14)\n",
    "\n",
    "# Create cartesian control (uses the quadruped's forward kinematics)\n",
    "import eagerx_tutorials.quadruped.cartesian_control\n",
    "cartesian_control = eagerx.Node.make(\"CartesiandPDController\", \"cartesian_control\", rate=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "643f2fa1-3386-455a-9fca-ce959c7a5d4a",
   "metadata": {},
   "source": [
    "We add the robot and the two nodes to an empty graph.\n",
    "\n",
    "Then, we connect the output of the central pattern generator (i.e. cartesian feet positions) to the cartesian controller, that in turn, maps them to desired joint positions that are passed to the quadruped's joint controller."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1ac3d496-dea2-4951-8ed0-af9384a3202e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize empty graph\n",
    "graph = eagerx.Graph.create([robot, cartesian_control, cpg])\n",
    "\n",
    "# Interconnect the nodes that results in an initial trot (that moves straight ahead).\n",
    "graph.connect(source=cpg.outputs.cartesian_pos, target=cartesian_control.inputs.cartesian_pos)\n",
    "graph.connect(source=cartesian_control.outputs.joint_pos, target=robot.actuators.joint_control)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "079a7647-2e09-45e6-9dfb-5f2432c61e06",
   "metadata": {},
   "source": [
    "This open-loop control strategy produces in the nominal case a **forward trot** as demonstrated by the two quadrupeds below:\n",
    "\n",
    "<img src=\"./figures/quad.gif\"/>\n",
    "\n",
    "However, we want the quadruped to make a **left-turn** instead!\n",
    "\n",
    "\n",
    "Therefore, we will define an environment action called `offset`. This offset will be added to the generated open-loop feet pattern.\n",
    "\n",
    "The offset action range (i.e. high & low) are chose to be relatively small (~1cm). Nonetheless, this should be enough to modify the pattern such that it makes the quadruped turn.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "749650cf-63e4-4f75-9600-a9439574cd41",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.connect(action=\"offset\", target=cpg.inputs.offset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d237e674-9062-4af1-aab2-746caa1940f4",
   "metadata": {},
   "source": [
    "Then, we connect the sensor as observations in the graph that we would like to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8a87a0db-72dd-4781-8e95-372edbd54b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the sensors that are to be used as observations\n",
    "# graph.connect(observation=\"joint_position\", source=robot.sensors.joint_position)\n",
    "# graph.connect(observation=\"joint_velocity\", source=robot.sensors.joint_velocity)\n",
    "# graph.connect(observation=\"position\", source=robot.sensors.position)\n",
    "graph.connect(observation=\"force_torque\", source=robot.sensors.force_torque)\n",
    "# graph.connect(observation=\"velocity\", source=robot.sensors.velocity)\n",
    "graph.connect(observation=\"orientation\", source=robot.sensors.orientation, window=2)\n",
    "\n",
    "# The open-loop pattern is probably also informative to determine relevant offsets.\n",
    "initial_obs = [-0.01354526, -0.26941818, 0.0552178, -0.25434446]\n",
    "graph.connect(observation=\"xs_zs\", source=cpg.outputs.xs_zs, skip=True, initial_obs=initial_obs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49af6935-07e5-4d40-81f4-4d75d863a109",
   "metadata": {},
   "source": [
    "We will also visualize the quadruped's movement during training. To reduce the computational overhead of rendering 3D images on the training speed, we will render the quadruped's (x,y) cartesian coordinates as a proxy instead.\n",
    "\n",
    "For this, we have already prepared the `XyPlane` node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "76360a0c-b549-494b-b05f-0b782bd69466",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create xy-plane render node\n",
    "import eagerx_tutorials.quadruped.overlay # Registers the xy plane node\n",
    "xy_plane = eagerx.Node.make(\"XyPlane\", \"xy_plane\", rate=5)\n",
    "\n",
    "# Add node to graph\n",
    "graph.add(xy_plane)\n",
    "\n",
    "# The node renders images, based on the x,y position sensor measurements.\n",
    "graph.connect(source=robot.sensors.position, target=xy_plane.inputs.position)\n",
    "\n",
    "# Select the output of the node for rendering.\n",
    "graph.render(xy_plane.outputs.image, rate=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28e7bce5-738c-4b99-8ca7-3bc74cdd788c",
   "metadata": {},
   "source": [
    "It is also possible to inspect the graph using the `eagerx-gui` package.\n",
    "\n",
    "It can be installed as follows:\n",
    "```bash\n",
    "pip3 install eagerx-gui\n",
    "```\n",
    "Jupyter notebooks have limited support for interactive applications, so we cannot open the GUI here.\n",
    "But if we were to run\n",
    "```python\n",
    "graph.gui()\n",
    "```\n",
    "If we select all the quadruped's sensors as observations, the gui would show the following:\n",
    "\n",
    "<img src=\"./figures/tutorial_2_gui.svg\" width=720>\n",
    "\n",
    "Here we see that the actions of the agent are outputs of *env/actions* and that the observations of the agent are inputs of *env/observations*.\n",
    "Also, the image output connected to *env/render* will be rendered.\n",
    "Note that *env/actions*, *env/observations* and *env/render* are connections of the `Graph` to the environment.\n",
    "They are split up in the GUI as nodes for visualization purposes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79848438-cffc-4a03-a075-faab20303565",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Environment definition\n",
    "Then, we define the environment that takes the graph and pybullet engine as input. The actions and observations of the environment are the ones we previously registered in the graph.\n",
    "\n",
    "\n",
    "### **Exercise 1**\n",
    "In this exercise, we are going to finish `QuadrupedEnv.step(action)` Specifically, we need to define a reward function that promotes offsets that make the quadruped's trot turn left. We will do so by specifying a reward function:\n",
    "- Estimate the current `yaw_rate` using the last two yaw sensor measurements. *hint: don't forget to multiply the difference with the sensor rate (`=20 Hz`)*.\n",
    "- Calculate the `desired_yaw_rate` (e.g. ~20 degrees) and convert it to radians. *hint: use `np.deg2rad(deg)` to convert degrees to radians.*\n",
    "- Define reward function as the negative squared error between the desired and actual yaw rate.\n",
    "- Add a little positive *alive* bonus (e.g. 0.25) to the reward, so that the quadruped does not fall down.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "61422b1b-032c-4c2c-97a4-38e45a613bcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARN] [1653176014.827049]: Adding state \"quadruped/image/pos\" to simulation node \"quadruped/image\" can potentially make the agnostic environment with object \"quadruped\" engine-specific. Check the spec of \"Quadruped\" under engine implementation \"PybulletEngine\" for more info.\n",
      "[WARN] [1653176014.828500]: Adding state \"quadruped/image/orientation\" to simulation node \"quadruped/image\" can potentially make the agnostic environment with object \"quadruped\" engine-specific. Check the spec of \"Quadruped\" under engine implementation \"PybulletEngine\" for more info.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] [1653176014.889730]: Node \"/QuadEnv/env/supervisor\" initialized.\n",
      "[INFO] [1653176015.048248]: Node \"/QuadEnv/engine\" initialized.\n",
      "[INFO] [1653176015.332893]: Node \"/QuadEnv/environment\" initialized.\n",
      "[INFO] [1653176015.487639]: Node \"/QuadEnv/cartesian_control\" initialized.\n",
      "TROT\n",
      "[INFO] [1653176015.554319]: Node \"/QuadEnv/cpg\" initialized.\n",
      "[INFO] [1653176015.556167]: Waiting for nodes \"['env/render']\" to be initialized.\n",
      "[INFO] [1653176015.591802]: Node \"/QuadEnv/xy_plane\" initialized.\n",
      "[INFO] [1653176015.760613]: Adding object \"quadruped\" of type \"Quadruped\" to the simulator.\n",
      "/home/bas/eagerx_dev/eagerx_tutorials/eagerx_tutorials/quadruped/go1/go1_description/urdf/go1.urdf\n",
      "[INFO] [1653176016.360124]: Node \"/QuadEnv/quadruped/joint_position\" initialized.\n",
      "[INFO] [1653176016.376369]: Node \"/QuadEnv/quadruped/joint_velocity\" initialized.\n",
      "[INFO] [1653176016.393423]: Node \"/QuadEnv/quadruped/force_torque\" initialized.\n",
      "[INFO] [1653176016.409283]: Node \"/QuadEnv/quadruped/orientation\" initialized.\n",
      "[INFO] [1653176016.425066]: Node \"/QuadEnv/quadruped/position\" initialized.\n",
      "[INFO] [1653176016.441563]: Node \"/QuadEnv/quadruped/velocity\" initialized.\n",
      "[INFO] [1653176016.464522]: Node \"/QuadEnv/quadruped/joint_control\" initialized.\n"
     ]
    }
   ],
   "source": [
    "# Define Gym Environment\n",
    "import pybullet\n",
    "import numpy as np\n",
    "import gym\n",
    "from typing import Dict, Tuple\n",
    "\n",
    "class QuadrupedEnv(eagerx.BaseEnv):\n",
    "    def __init__(self, name, rate, graph, engine, episode_timeout):\n",
    "        super(QuadrupedEnv, self).__init__(name, rate, graph, engine, force_start=True)\n",
    "        self.steps = None\n",
    "        self.timeout_steps = int(episode_timeout * rate)\n",
    "        self.rate = rate  # [Hz] Sensor rate\n",
    "\n",
    "    @property\n",
    "    def observation_space(self) -> gym.spaces.Dict:\n",
    "        \"\"\"The Space object corresponding to valid observations.\n",
    "\n",
    "        Per default, the observation space of all registered observations in the graph is used.\n",
    "        \"\"\"\n",
    "        return self._observation_space\n",
    "\n",
    "    @property\n",
    "    def action_space(self) -> gym.spaces.Dict:\n",
    "        \"\"\"The Space object corresponding to valid actions\n",
    "\n",
    "        Per default, the action space of all registered actions in the graph is used.\n",
    "        \"\"\"\n",
    "        return self._action_space\n",
    "\n",
    "    def reset(self):\n",
    "        \"\"\"A method that resets the environment to an initial state and returns an initial observation.\"\"\"\n",
    "        # Reset number of steps\n",
    "        self.steps = 0\n",
    "\n",
    "        # Sample desired states\n",
    "        states = self.state_space.sample()\n",
    "\n",
    "        # Perform reset\n",
    "        obs = self._reset(states)\n",
    "        return obs\n",
    "\n",
    "    def step(self, action: Dict) -> Tuple[Dict, float, bool, Dict]:\n",
    "        \"\"\"A method that runs one timestep of the environment's dynamics.\"\"\"\n",
    "        \n",
    "        # Here, we apply a step (i.e. we step the graph dynamics).\n",
    "        # It returns a dict containing measurements of all registered observations.\n",
    "        obs = self._step(action)\n",
    "        self.steps += 1\n",
    "\n",
    "        # We have access to the last two orientation sensor measurements, \n",
    "        # because we used window=2 when connecting `orientation` as an observation in the graph.\n",
    "        _, _, prev_yaw = pybullet.getEulerFromQuaternion(obs[\"orientation\"][-2])\n",
    "        roll, pitch, yaw = pybullet.getEulerFromQuaternion(obs[\"orientation\"][-1])\n",
    "        \n",
    "        # YOUR CODE HERE\n",
    "        # 1. Calculate the yaw rate using prev_yaw and yaw (don't forget to scale with self.rate).\n",
    "        # 2. Calculate the desired yaw_rate (20 degrees) in radians.\n",
    "        # 3. Calculate the negative squared error between the desired and actual yaw rate.\n",
    "        # 4. Add a little alive bonus to promote not falling down.\n",
    "        yaw_rate = (yaw - prev_yaw) * self.rate\n",
    "        desired_yaw_rate = np.deg2rad(20) # [rad] Desired yaw rate\n",
    "        yaw_cost = (yaw_rate - desired_yaw_rate) ** 2\n",
    "        alive_bonus = 0.25\n",
    "        reward = alive_bonus - yaw_cost\n",
    "        # END OF YOUR CODE\n",
    "\n",
    "        # Determine termination condition\n",
    "        has_fallen = abs(np.rad2deg(roll)) > 40 or abs(np.rad2deg(pitch)) > 40\n",
    "        timeout = self.steps >= self.timeout_steps\n",
    "\n",
    "        # Determine done flag\n",
    "        done = timeout or has_fallen\n",
    "        \n",
    "        # Set info about episode truncation\n",
    "        info = {\"TimeLimit.truncated\": timeout and not has_fallen}\n",
    "        return obs, reward, done, info\n",
    "\n",
    "# Define the pybullet engine\n",
    "import eagerx_pybullet.engine  # Registers PybulletEngine\n",
    "engine = eagerx.Engine.make(\"PybulletEngine\", rate=200, gui=False, egl=False, process=eagerx.process.ENVIRONMENT)    \n",
    "\n",
    "# Initialize Environment\n",
    "episode_timeout = 10  # [s] number of seconds before timing-out an episode.\n",
    "env = QuadrupedEnv(name=\"QuadEnv\", rate=20, graph=graph, engine=engine, episode_timeout=episode_timeout)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c4550af-9c3b-4d0e-91d6-2ce16b41e460",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Training\n",
    "\n",
    "<img src=\"./figures/train_eps_3.gif\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cd5a8911-13da-46c2-8b50-fc1d9b3244c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "[INFO] [1653176031.149196]: Nodes initialized.\n",
      "[INFO] [1653176031.423836]: Pipelines initialized.\n",
      "argv[0]=\n",
      "argv[0]=\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 200      |\n",
      "|    ep_rew_mean     | 4.39     |\n",
      "| time/              |          |\n",
      "|    episodes        | 4        |\n",
      "|    fps             | 16       |\n",
      "|    time_elapsed    | 48       |\n",
      "|    total_timesteps | 800      |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -21.3    |\n",
      "|    critic_loss     | 0.397    |\n",
      "|    ent_coef        | 0.402    |\n",
      "|    ent_coef_loss   | -5.97    |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 870      |\n",
      "|    std             | 0.05     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 200      |\n",
      "|    ep_rew_mean     | 7.3      |\n",
      "| time/              |          |\n",
      "|    episodes        | 8        |\n",
      "|    fps             | 17       |\n",
      "|    time_elapsed    | 92       |\n",
      "|    total_timesteps | 1600     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -24.4    |\n",
      "|    critic_loss     | 0.188    |\n",
      "|    ent_coef        | 0.147    |\n",
      "|    ent_coef_loss   | -11.8    |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 1870     |\n",
      "|    std             | 0.0502   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 200      |\n",
      "|    ep_rew_mean     | 9.08     |\n",
      "| time/              |          |\n",
      "|    episodes        | 12       |\n",
      "|    fps             | 17       |\n",
      "|    time_elapsed    | 138      |\n",
      "|    total_timesteps | 2400     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -21.2    |\n",
      "|    critic_loss     | 0.0946   |\n",
      "|    ent_coef        | 0.0564   |\n",
      "|    ent_coef_loss   | -17.3    |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 2870     |\n",
      "|    std             | 0.0502   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 200      |\n",
      "|    ep_rew_mean     | 10.7     |\n",
      "| time/              |          |\n",
      "|    episodes        | 16       |\n",
      "|    fps             | 16       |\n",
      "|    time_elapsed    | 189      |\n",
      "|    total_timesteps | 3200     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -16.9    |\n",
      "|    critic_loss     | 0.0628   |\n",
      "|    ent_coef        | 0.0232   |\n",
      "|    ent_coef_loss   | -18.7    |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 3870     |\n",
      "|    std             | 0.05     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 200      |\n",
      "|    ep_rew_mean     | 11.2     |\n",
      "| time/              |          |\n",
      "|    episodes        | 20       |\n",
      "|    fps             | 16       |\n",
      "|    time_elapsed    | 244      |\n",
      "|    total_timesteps | 4000     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -13.3    |\n",
      "|    critic_loss     | 0.0491   |\n",
      "|    ent_coef        | 0.0104   |\n",
      "|    ent_coef_loss   | -15.7    |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 4870     |\n",
      "|    std             | 0.0496   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 200      |\n",
      "|    ep_rew_mean     | 12.4     |\n",
      "| time/              |          |\n",
      "|    episodes        | 24       |\n",
      "|    fps             | 16       |\n",
      "|    time_elapsed    | 294      |\n",
      "|    total_timesteps | 4800     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -10.7    |\n",
      "|    critic_loss     | 0.0389   |\n",
      "|    ent_coef        | 0.00547  |\n",
      "|    ent_coef_loss   | -10      |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 5870     |\n",
      "|    std             | 0.0486   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 200      |\n",
      "|    ep_rew_mean     | 13.7     |\n",
      "| time/              |          |\n",
      "|    episodes        | 28       |\n",
      "|    fps             | 16       |\n",
      "|    time_elapsed    | 336      |\n",
      "|    total_timesteps | 5600     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -9.01    |\n",
      "|    critic_loss     | 0.0349   |\n",
      "|    ent_coef        | 0.00355  |\n",
      "|    ent_coef_loss   | -3.35    |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 6870     |\n",
      "|    std             | 0.0472   |\n",
      "---------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Stable-baselines\n",
    "from sb3_contrib import TQC\n",
    "from eagerx.wrappers import Flatten\n",
    "\n",
    "# Define hyper parameters for the TQC policy.\n",
    "hyperparams = dict(\n",
    "    learning_rate=1e-3,\n",
    "    tau=0.02,\n",
    "    gamma=0.98,\n",
    "    buffer_size=300000,\n",
    "    learning_starts=100,\n",
    "    use_sde=True,\n",
    "    use_sde_at_warmup=True,\n",
    "    train_freq=8,\n",
    "    gradient_steps=10,\n",
    "    verbose=1,\n",
    "    top_quantiles_to_drop_per_net=0,\n",
    "    policy_kwargs=dict(n_critics=1, net_arch=dict(pi=[64, 64], qf=[64, 64])),\n",
    ")\n",
    "\n",
    "# Initialize the model\n",
    "model = TQC(\"MlpPolicy\", Flatten(env), **hyperparams)\n",
    "\n",
    "# Train for 30 episodes\n",
    "train_episodes = 30\n",
    "try:\n",
    "    train_steps = int(train_episodes * episode_timeout * 20)\n",
    "    # Render top-view of the quadruped's movement\n",
    "    env.render(\"human\")\n",
    "    # Start training!\n",
    "    model.learn(train_steps)\n",
    "    # Save the final policy\n",
    "    model.save(\"last_policy\")\n",
    "except KeyboardInterrupt:\n",
    "    model.save(\"last_policy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ee50052-611e-4246-8000-17f740d8327d",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Evaluation\n",
    "\n",
    "<img src=\"./figures/eval_eps_4.gif\"/>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a43fe7-4c41-4215-8f64-f419d63ca7f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARN] [1653176554.888343]: Adding state \"quadruped/image/pos\" to simulation node \"quadruped/image\" can potentially make the agnostic environment with object \"quadruped\" engine-specific. Check the spec of \"Quadruped\" under engine implementation \"PybulletEngine\" for more info.\n",
      "[WARN] [1653176554.889516]: Adding state \"quadruped/image/orientation\" to simulation node \"quadruped/image\" can potentially make the agnostic environment with object \"quadruped\" engine-specific. Check the spec of \"Quadruped\" under engine implementation \"PybulletEngine\" for more info.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] [1653176554.942069]: Node \"/QuadEnv_eval/env/supervisor\" initialized.\n",
      "argv[0]=\n",
      "argv[0]=\n",
      "[INFO] [1653176555.101325]: Node \"/QuadEnv_eval/engine\" initialized.\n",
      "[INFO] [1653176555.289906]: Node \"/QuadEnv_eval/environment\" initialized.\n",
      "[INFO] [1653176555.408301]: Node \"/QuadEnv_eval/cartesian_control\" initialized.\n",
      "TROT\n",
      "[INFO] [1653176555.476807]: Node \"/QuadEnv_eval/cpg\" initialized.\n",
      "[INFO] [1653176555.695379]: Adding object \"quadruped\" of type \"Quadruped\" to the simulator.\n",
      "/home/bas/eagerx_dev/eagerx_tutorials/eagerx_tutorials/quadruped/go1/go1_description/urdf/go1.urdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bas/.cache/pypoetry/virtualenvs/eagerx-tutorials-uyJhHlY9-py3.8/lib/python3.8/site-packages/stable_baselines3/common/evaluation.py:65: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] [1653176555.946218]: Node \"/QuadEnv_eval/quadruped/joint_position\" initialized.\n",
      "[INFO] [1653176555.966999]: Node \"/QuadEnv_eval/quadruped/joint_velocity\" initialized.\n",
      "[INFO] [1653176555.988785]: Node \"/QuadEnv_eval/quadruped/force_torque\" initialized.\n",
      "[INFO] [1653176556.005551]: Node \"/QuadEnv_eval/quadruped/orientation\" initialized.\n",
      "[INFO] [1653176556.023348]: Node \"/QuadEnv_eval/quadruped/position\" initialized.\n",
      "[INFO] [1653176556.040077]: Node \"/QuadEnv_eval/quadruped/velocity\" initialized.\n",
      "[INFO] [1653176556.057581]: Node \"/QuadEnv_eval/quadruped/joint_control\" initialized.\n",
      "[INFO] [1653176556.083647]: Node \"/QuadEnv_eval/quadruped/image\" initialized.\n",
      "[INFO] [1653176557.411853]: Nodes initialized.\n",
      "[INFO] [1653176557.694686]: Pipelines initialized.\n"
     ]
    }
   ],
   "source": [
    "# Evaluate\n",
    "from eagerx_tutorials.quadruped.evaluate import EvaluateEnv\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "\n",
    "engine = eagerx.Engine.make(\"PybulletEngine\", rate=200, gui=False, egl=False, process=eagerx.process.ENVIRONMENT)\n",
    "eval_env = EvaluateEnv(env, engine, episode_timeout=40, render=\"pybullet\")\n",
    "eval_env.render(\"human\")\n",
    "path = \"last_policy\"\n",
    "# path = \"logs/Quadruped_1/rl_model_6000_steps\"\n",
    "model = TQC.load(path)\n",
    "mean_reward, std = evaluate_policy(model, Flatten(eval_env), n_eval_episodes=5)\n",
    "print(f\"Mean reward = {mean_reward:.2f} +/- {std}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1f4e43f-dc80-43d9-9fa5-30ec7a7490c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
