{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "65b4e05a",
   "metadata": {},
   "source": [
    "# Tutorial 1: Environment Creation and Training\n",
    "\n",
    "In this tutorial, we will show a simple example of how to create a gym environment using [EAGERx](https://eagerx.readthedocs.io/en/master/).\n",
    "Also, we will use this environment to train a policy using [Stable Baselines 3](https://stable-baselines3.readthedocs.io/en/master/).\n",
    "\n",
    "The following will be covered:\n",
    "- Creating a [Graph](https://eagerx.readthedocs.io/en/master/guide/api_reference/graph/graph.html) with an [Object](https://eagerx.readthedocs.io/en/master/guide/api_reference/object/index.html)\n",
    "- How to use this [Graph](https://eagerx.readthedocs.io/en/master/guide/api_reference/graph/graph.html) and a [Engine](https://eagerx.readthedocs.io/en/master/guide/api_reference/engine/index.html) to create an [Eagerx Environment](https://eagerx.readthedocs.io/en/master/guide/api_reference/env/index.html)\n",
    "- How to train a policy with the [EAGERx Environment](https://eagerx.readthedocs.io/en/master/guide/api_reference/env/index.html)\n",
    "\n",
    "In the remainder of this tutorial we will go more into detail on these concepts.\n",
    "\n",
    "\n",
    "## Pendulum Swing-up\n",
    "\n",
    "We will create an environment for solving the classic control problem of swinging up an underactuated pendulum, very similar to the [Pendulum-v1 environment](https://www.gymlibrary.ml/environments/classic_control/pendulum/).\n",
    "Our goal is to swing up this pendulum to the upright position and keep it there, while minimizing the velocity of the pendulum and the input voltage.\n",
    "\n",
    "Since the dynamics of a pendulum actuated by a DC motor are well known, we can simulate the pendulum by integrating the corresponding ordinary differential equations (ODEs):\n",
    "\n",
    "\n",
    "$\\mathbf{x} = \\begin{bmatrix} \\theta \\\\ \\dot{\\theta} \\end{bmatrix} \\\\ \\dot{\\mathbf{x}} = \\begin{bmatrix} \\dot{\\theta} \\\\ \\frac{1}{J}(\\frac{K}{R}u - mgl \\sin{\\theta} - b \\dot{\\theta} - \\frac{K^2}{R}\\dot{\\theta})\\end{bmatrix}$\n",
    "\n",
    "with $\\theta$ the angle w.r.t. upright position, $\\dot{\\theta}$ the angular velocity, $u$ the input voltage, $J$ the inertia, $m$ the mass, $g$ the gravitational constant, $l$ the length of the pendulum, $b$ the motor viscous friction constant, $K$ the motor constant and $R$ the electric resistance.\n",
    "\n",
    "<img src=\"./figures/pendulum.GIF\" width=\"480\" />\n",
    "\n",
    "\n",
    "## Activate GPU (Colab only)\n",
    "\n",
    "When in Colab, you'll need to enable GPUs for the notebook:\n",
    "\n",
    "- Navigate to Editâ†’Notebook Settings\n",
    "- select GPU from the Hardware Accelerator drop-down\n",
    "\n",
    "\n",
    "## Notebook Setup\n",
    "\n",
    "In order to be able to run the code, we need to install the *eagerx_tutorials* package and ROS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b7485878-73c8-43fc-8b9a-a8fc9d8e1775",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not running on CoLab.\n",
      "Execute ROS commands as \"!...\".\n",
      "ROS noetic available.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    import eagerx_tutorials\n",
    "except ImportError:\n",
    "    !{\"echo 'Installing eagerx-tutorials with pip.' && pip install eagerx-tutorials >> /tmp/eagerx_install.txt 2>&1\"}\n",
    "if 'google.colab' in str(get_ipython()):\n",
    "    !{\"curl 'https://raw.githubusercontent.com/eager-dev/eagerx_tutorials/master/scripts/setup_colab.sh' > ~/setup_colab.sh\"}\n",
    "    !{\"bash ~/setup_colab.sh\"}\n",
    "\n",
    "# Setup interactive notebook\n",
    "# Required in interactive notebooks only.\n",
    "from eagerx_tutorials import helper\n",
    "helper.setup_notebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5627eb51",
   "metadata": {},
   "source": [
    "## Let's get started\n",
    "\n",
    "First we will import EAGERx and initialize it.\n",
    "As mentioned before, EAGERx makes use of ROS functionality for communication and during initialization a ROS master is started if there isn't one running already."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f0faf969",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... logging to /home/jelle/.ros/log/39a87530-dc2b-11ec-9aaf-cbc881d02458/roslaunch-jelle-Alienware-m15-R4-12087.log\n",
      "\u001b[1mstarted roslaunch server http://10.152.153.161:38351/\u001b[0m\n",
      "ros_comm version 1.15.14\n",
      "\n",
      "\n",
      "SUMMARY\n",
      "========\n",
      "\n",
      "PARAMETERS\n",
      " * /rosdistro: noetic\n",
      " * /rosversion: 1.15.14\n",
      "\n",
      "NODES\n",
      "\n",
      "auto-starting new master\n",
      "\u001b[1mprocess[master]: started with pid [12140]\u001b[0m\n",
      "\u001b[1mROS_MASTER_URI=http://localhost:11311\u001b[0m\n",
      "\u001b[1msetting /run_id to 39a87530-dc2b-11ec-9aaf-cbc881d02458\u001b[0m\n",
      "\u001b[1mprocess[rosout-1]: started with pid [12165]\u001b[0m\n",
      "started core service [/rosout]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<roslaunch.parent.ROSLaunchParent at 0x7f0c14201a60>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import eagerx\n",
    "# Initialize eagerx (starts roscore if not already started.)\n",
    "eagerx.initialize(\"eagerx_core\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "701e0a93",
   "metadata": {},
   "source": [
    "An `Object` is an entity that has inputs (sensors), outputs (actuators) and states (that can be reset at the beginning of an episode).\n",
    "\n",
    "We are going to create one object (the pendulum). For this first tutorial, we don't want to go into details too much and start with existing objects.\n",
    "Note that we import the pendulum.\n",
    "While this might look like an unused import, it is not.\n",
    "During the import, the pendulum object is registered and we can therefore make it based on its ID, i.e. *Pendulum*.\n",
    "\n",
    "Before making the object, we will first obtain some info on the *Pendulum*, such that we know with what arguments we should make it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eeaac748",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registered entity_id=`Pendulum`:\n",
      "   entity_type: `Object`\n",
      "   module: `eagerx_tutorials.pendulum.objects`\n",
      "   file: `/home/jelle/eagerx_dev/eagerx_tutorials/eagerx_tutorials/pendulum/objects.py`\n",
      "\n",
      "Supported engines:\n",
      " - OdeEngine\n",
      "\n",
      "Make this spec with (use `entity_id: str = \"Pendulum\"`):\n",
      "   spec = Object.make(entity_id: str, name: str, actuators: List[str] = None, sensors: List[str] = None, states: List[str] = None, rate: float = 30.0, render_shape: List[int] = None, render_fn: str = None)\n",
      "\n",
      "class Pendulum(Object):\n",
      "   spec(spec: eagerx.core.specs.ObjectSpec, name: str, actuators: List[str] = None, sensors: List[str] = None, states: List[str] = None, rate: float = 30.0, render_shape: List[int] = None, render_fn: str = None):\n",
      "      docs:\n",
      "         Object spec of Pendulum\n",
      "\n",
      "   agnostic(spec: eagerx.core.specs.ObjectSpec, rate: float):\n",
      "      config:\n",
      "       - render_shape: [480, 480]\n",
      "       - render_fn: pendulum_render_fn\n",
      "      sensors:\n",
      "       - theta: <class 'std_msgs.msg._Float32.Float32'>\n",
      "       - dtheta: <class 'std_msgs.msg._Float32.Float32'>\n",
      "       - image: <class 'sensor_msgs.msg._Image.Image'>\n",
      "       - u_applied: <class 'std_msgs.msg._Float32MultiArray.Float32MultiArray'>\n",
      "      actuators:\n",
      "       - u: <class 'std_msgs.msg._Float32MultiArray.Float32MultiArray'>\n",
      "      engine_states:\n",
      "       - model_state: <class 'std_msgs.msg._Float32MultiArray.Float32MultiArray'>\n",
      "       - model_parameters: <class 'std_msgs.msg._Float32MultiArray.Float32MultiArray'>\n",
      "       - mass: <class 'std_msgs.msg._Float32.Float32'>\n",
      "       - length: <class 'std_msgs.msg._Float32.Float32'>\n",
      "       - max_speed: <class 'std_msgs.msg._Float32.Float32'>\n",
      "      docs:\n",
      "         Agnostic definition of the Pendulum.\n",
      "\n",
      "                 Sensors\n",
      "                 theta: angle of the pendulum wrt upward position\n",
      "                 dtheta: angular velocity of the pendulum\n",
      "                 image: render of pendulum system\n",
      "                 u_applied: Applied DC motor voltage\n",
      "\n",
      "                 Actuators\n",
      "                 u: DC motor voltage\n",
      "\n",
      "                 States\n",
      "                 model_state: allows resetting the angle and angular velocity\n",
      "                 model_parameters: allows resetting all ODE parameters [J, m, l, b, K, R, c, d].\n",
      "                 mass: allows resetting the mass of the Gym pendulum m\n",
      "                 length: allows resetting the length of the Gym pendulum l\n",
      "                 max_speed: allows resetting the max speed of the Gym pendulum\n",
      "\n",
      "                 Config\n",
      "                 render_shape: shape of render window [height, width]\n",
      "        \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import eagerx_tutorials.pendulum  # Registers Pendulum\n",
    "\n",
    "eagerx.Object.info(\"Pendulum\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94acafd2-ea83-4bfe-aeb1-76fa251fec47",
   "metadata": {},
   "source": [
    "We see that the `eagerx.Object.info(\"Pendulum\")` provides us information on the *Pendulum* object.\n",
    "It has four sensors (*theta*, *dtheta*, *image*, *u_applied*), one actuator (*u*) and two states (*model_state*, *model_parameters*).\n",
    "Here *theta*, *dtheta* and *u* correspond to $\\theta$, $\\dot{\\theta}$ and $u$, respectively.\n",
    "For now, we are only interested in how to make this object, other information will be covered in later tutorials.\n",
    "We can make the *Pendulum* object with the `eagerx.Object.make` method with the required arguments *entity_id* and (a unique) *name*.\n",
    "Furthermore, we will specify which actuators, sensors and states we will use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "da5a5a0e-6502-4ac1-9b27-c3e207a8c47b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make pendulum\n",
    "pendulum = eagerx.Object.make(\"Pendulum\", \"pendulum\", actuators=[\"u\"], sensors=[\"theta\", \"dtheta\", \"image\"], states=[\"model_state\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d2f0c2d",
   "metadata": {},
   "source": [
    "Next, we create a [Graph](https://eagerx.readthedocs.io/en/master/guide/api_reference/graph/graph.html) and add the pendulum to it.\n",
    "\n",
    "The graph describes the interconnection of nodes and objects.\n",
    "In this way, the creation of an environment becomes modular.\n",
    "This allows users to create an implementation for nodes and objects once, and easily create new environments by reusing these implementations.\n",
    "Also, this allows to construct complex environments using nodes and objects as basic building blocks.\n",
    "\n",
    "After adding the pendulum to the graph, we will connect the actuator *u* to a new action called *voltage*.\n",
    "We will connect the sensors *theta* and *dtheta* to the observations *angle* and *angular_velocity*, respectively.\n",
    "In this way, the agent will be able to send actions to control $u$ of the pendulum and observe $\\theta$ and $\\dot{\\theta}$.\n",
    "\n",
    "Finally, we will also render the *image* sensor in order to visualize the pendulum.\n",
    "More detailed information on rendering is covered in another tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2686fa8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define rate (depends on rate of ode)\n",
    "rate = 30.0\n",
    "\n",
    "# Initialize empty graph\n",
    "graph = eagerx.Graph.create()\n",
    "\n",
    "# Add pendulum to the graph\n",
    "graph.add(pendulum)\n",
    "\n",
    "# Connect the pendulum to an action and observation\n",
    "graph.connect(action=\"voltage\", target=pendulum.actuators.u)\n",
    "graph.connect(source=pendulum.sensors.theta, observation=\"angle\")\n",
    "graph.connect(source=pendulum.sensors.dtheta, observation=\"angular_velocity\")\n",
    "\n",
    "# Render image\n",
    "graph.render(source=pendulum.sensors.image, rate=rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99f0b265",
   "metadata": {},
   "source": [
    "It is also possible to inspect the graph using the eagerx-gui package.\n",
    "It can be installed as follows:\n",
    "```bash\n",
    "pip3 install eagerx-gui\n",
    "```\n",
    "Jupyter notebooks have limited support for interactive applications, so we cannot open the GUI here.\n",
    "But if we were to run\n",
    "```python\n",
    "graph.gui()\n",
    "```\n",
    "The ouput would be as follows:\n",
    "\n",
    "<img src=\"./figures/tutorial_1_gui.svg\" width=720>\n",
    "\n",
    "Here we see that the actions of the agent are outputs of *env/actions* and that the observations of the agent are inputs of *env/observations*.\n",
    "Also, we could render output by connecting to *env/render*, which will be covered in another tutorial.\n",
    "Note that *env/actions*, *env/observations* and *env/render* represent connections of the `Graph` to the environment.\n",
    "They are split up in the GUI as nodes for visualization purposes.\n",
    "\n",
    "Next, we will create the [Environment](https://eagerx.readthedocs.io/en/master/guide/api_reference/env/index.html).\n",
    "Environment creation in EAGERx follows the same API as Gym, i.e. we have to define a [step()](https://eagerx.readthedocs.io/en/master/guide/api_reference/env/index.html#eagerx.core.env.BaseEnv.step) and [reset()](https://eagerx.readthedocs.io/en/master/guide/api_reference/env/index.html#eagerx.core.env.BaseEnv.reset) method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7e829569-62a0-40a6-ab0d-261daa505cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class PendulumEnv(eagerx.BaseEnv):\n",
    "    def __init__(self, name: str, rate: float, graph: eagerx.Graph, engine: eagerx.Engine):\n",
    "        \"\"\"Initializes an environment with EAGERx dynamics.\n",
    "\n",
    "        :param name: The name of the environment. Everything related to this environment\n",
    "                     (parameters, topics, nodes, etc...) will be registered under namespace: \"/[name]\".\n",
    "        :param rate: The rate (Hz) at which the environment will run.\n",
    "        :param graph: The graph consisting of nodes and objects that describe the environment's dynamics.\n",
    "        :param engine: The physics engine that will govern the environment's dynamics.\n",
    "        \"\"\"\n",
    "        self.eval = eval\n",
    "        \n",
    "        # Maximum episode length\n",
    "        self.max_steps = 100\n",
    "        \n",
    "        # Step counter\n",
    "        self.steps = None\n",
    "        super().__init__(name, rate, graph, engine, force_start=True)\n",
    "    \n",
    "    def step(self, action: Dict):\n",
    "        \"\"\"A method that runs one timestep of the environment's dynamics.\n",
    "\n",
    "        :params action: A dictionary of actions provided by the agent.\n",
    "        :returns: A tuple (observation, reward, done, info).\n",
    "\n",
    "            - observation: Dictionary of observations of the current timestep.\n",
    "\n",
    "            - reward: amount of reward returned after previous action\n",
    "\n",
    "            - done: whether the episode has ended, in which case further step() calls will return undefined results\n",
    "\n",
    "            - info: contains auxiliary diagnostic information (helpful for debugging, and sometimes learning)\n",
    "        \"\"\"\n",
    "        # Take step\n",
    "        observation = self._step(action)\n",
    "        self.steps += 1\n",
    "        \n",
    "        # Get angle and angular velocity\n",
    "        # Take first element because of window size (covered in other tutorial)\n",
    "        th = observation[\"angle\"][0] \n",
    "        thdot = observation[\"angular_velocity\"][0]\n",
    "\n",
    "        # Convert from numpy array to float\n",
    "        u = float(action[\"voltage\"])\n",
    "\n",
    "        # Normalize angle so it lies in [-pi, pi]\n",
    "        th -= 2 * np.pi * np.floor((th + np.pi) / (2 * np.pi))\n",
    "\n",
    "        # Calculate cost\n",
    "        # Penalize angle error, angular velocity and input voltage\n",
    "        cost = th**2 + 0.1 * thdot**2 + 0.001 * u**2  \n",
    "\n",
    "        # Determine when is the episode over\n",
    "        # currently just a timeout after 100 steps\n",
    "        done = self.steps > self.max_steps\n",
    "\n",
    "        # Set info, tell the algorithm the termination was due to a timeout\n",
    "        # (the episode was truncated)\n",
    "        info = {\"TimeLimit.truncated\": self.steps > self.max_steps}\n",
    "        \n",
    "        return observation, -cost, done, info\n",
    "    \n",
    "    def reset(self) -> Dict:\n",
    "        \"\"\"Resets the environment to an initial state and returns an initial observation.\n",
    "\n",
    "        :returns: The initial observation.\n",
    "        \"\"\"\n",
    "        # Determine reset states\n",
    "        states = self.state_space.sample()\n",
    "            \n",
    "        # Perform reset\n",
    "        observation = self._reset(states)\n",
    "\n",
    "        # Reset step counter\n",
    "        self.steps = 0\n",
    "        return observation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8410ce6",
   "metadata": {},
   "source": [
    "Next, we will create the [Engine](https://eagerx.readthedocs.io/en/master/guide/api_reference/engine/index.html).\n",
    "Since objects can have implementions for multiple physics engines and real systems, we need to initialize the appropriate engine.\n",
    "In our case, we will use the [OdeEngine](https://github.com/eager-dev/eagerx_ode), which allows to simulate systems based on ordinary differential equations (ODEs).\n",
    "In other tutorials we will go more into detail on the engine and how you can create your own engine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "badb2076",
   "metadata": {},
   "outputs": [],
   "source": [
    "import eagerx_ode  # Registers OdeEngine\n",
    "\n",
    "# Define engines\n",
    "engine = eagerx.Engine.make(\"OdeEngine\", rate=rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0c48b43",
   "metadata": {},
   "source": [
    "Just like in normal Gym environments, we will create a step function in which we will calculate the reward at each time step and check for termination conditions.\n",
    "Our goal is to stabilize the pendulum in upright position, while minimizing the input voltage that is applied.\n",
    "Therefore we choose a reward function that is a weighted sum of $\\theta^2$, $\\dot{\\theta^2}$ and $u^2$. \n",
    "\n",
    "Note that we can obtain the values of the actions and observations using the keys *voltage*, *angle* and *angular_velocity*, which correspond to the names of the actions and observations above in the screenshot of the GUI."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06ae7093",
   "metadata": {},
   "source": [
    "Having created a graph, an engine and a step function, we can now construct the EAGERx environment.\n",
    "We can use it like any other Gym environment.\n",
    "Here we will now train a policy to swing up the pendulum using the Soft Actor Critic (SAC) reinforcement learning algorithm implementation from [Stable Baselines 3](https://stable-baselines3.readthedocs.io/en/master/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "19aaa2b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] [1653483875.887615]: Node \"/PendulumEnv/env/supervisor\" initialized.\n",
      "[INFO] [1653483876.040063]: Node \"/PendulumEnv/engine\" initialized.\n",
      "[INFO] [1653483876.207828]: Node \"/PendulumEnv/environment\" initialized.\n",
      "[INFO] [1653483876.304769]: Node \"/PendulumEnv/pendulum/theta\" initialized.\n",
      "[INFO] [1653483876.346392]: Waiting for nodes \"['env/render']\" to be initialized.\n",
      "[INFO] [1653483876.362410]: Node \"/PendulumEnv/pendulum/dtheta\" initialized.\n",
      "Using cuda device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "[INFO] [1653483876.467694]: Adding object \"pendulum\" of type \"Pendulum\" to the simulator.\n",
      "[INFO] [1653483876.487797]: Node \"/PendulumEnv/pendulum/x\" initialized.\n",
      "[INFO] [1653483876.511564]: [pendulum/image] START RENDERING!\n",
      "[INFO] [1653483876.512159]: Node \"/PendulumEnv/pendulum/image\" initialized.\n",
      "[INFO] [1653483876.539035]: Node \"/PendulumEnv/pendulum/u\" initialized.\n",
      "[INFO] [1653483876.557002]: Node \"/PendulumEnv/pendulum/u_applied\" initialized.\n",
      "[INFO] [1653483879.838526]: Nodes initialized.\n",
      "[INFO] [1653483879.902243]: Pipelines initialized.\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 101       |\n",
      "|    ep_rew_mean     | -1.01e+03 |\n",
      "| time/              |           |\n",
      "|    episodes        | 4         |\n",
      "|    fps             | 76        |\n",
      "|    time_elapsed    | 5         |\n",
      "|    total_timesteps | 404       |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 17.7      |\n",
      "|    critic_loss     | 13.3      |\n",
      "|    ent_coef        | 0.917     |\n",
      "|    ent_coef_loss   | -0.117    |\n",
      "|    learning_rate   | 0.0003    |\n",
      "|    n_updates       | 303       |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 101      |\n",
      "|    ep_rew_mean     | -964     |\n",
      "| time/              |          |\n",
      "|    episodes        | 8        |\n",
      "|    fps             | 72       |\n",
      "|    time_elapsed    | 11       |\n",
      "|    total_timesteps | 808      |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 31.4     |\n",
      "|    critic_loss     | 15.8     |\n",
      "|    ent_coef        | 0.831    |\n",
      "|    ent_coef_loss   | -0.218   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 707      |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 101      |\n",
      "|    ep_rew_mean     | -952     |\n",
      "| time/              |          |\n",
      "|    episodes        | 12       |\n",
      "|    fps             | 71       |\n",
      "|    time_elapsed    | 16       |\n",
      "|    total_timesteps | 1212     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 48.8     |\n",
      "|    critic_loss     | 26.5     |\n",
      "|    ent_coef        | 0.743    |\n",
      "|    ent_coef_loss   | -0.311   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 1111     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 101      |\n",
      "|    ep_rew_mean     | -950     |\n",
      "| time/              |          |\n",
      "|    episodes        | 16       |\n",
      "|    fps             | 70       |\n",
      "|    time_elapsed    | 22       |\n",
      "|    total_timesteps | 1616     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 65.8     |\n",
      "|    critic_loss     | 31.9     |\n",
      "|    ent_coef        | 0.662    |\n",
      "|    ent_coef_loss   | -0.443   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 1515     |\n",
      "---------------------------------\n",
      "[INFO] [1653483905.346225]: [PendulumEnv] Send termination signal to '/PendulumEnv/env/render'.\n",
      "[INFO] [1653483905.347012]: [PendulumEnv][/PendulumEnv/engine] Shutting down.\n",
      "[INFO] [1653483905.347702]: [/PendulumEnv/engine] Shutting down '/PendulumEnv/pendulum/x'.\n",
      "[INFO] [1653483905.348333]: [/PendulumEnv/pendulum/x] Shutting down.\n",
      "[INFO] [1653483905.408651]: [/PendulumEnv/engine] Shutting down '/PendulumEnv/pendulum/image'.\n",
      "[INFO] [1653483905.409473]: [/PendulumEnv/pendulum/image] Shutting down.\n",
      "[INFO] [1653483905.411023]: [/PendulumEnv/engine] Shutting down '/PendulumEnv/pendulum/u'.\n",
      "[INFO] [1653483905.411681]: [/PendulumEnv/pendulum/u] Shutting down.\n",
      "[INFO] [1653483905.412455]: [/PendulumEnv/engine] Shutting down '/PendulumEnv/pendulum/u_applied'.\n",
      "[INFO] [1653483905.413103]: [/PendulumEnv/pendulum/u_applied] Shutting down.\n",
      "[INFO] [1653483905.413821]: [/PendulumEnv/engine] Shutting down.\n",
      "[INFO] [1653483905.415179]: [PendulumEnv][/PendulumEnv/pendulum/theta] Shutting down.\n",
      "[INFO] [1653483905.415786]: [/PendulumEnv/pendulum/theta] Shutting down.\n",
      "[INFO] [1653483905.416456]: [PendulumEnv][/PendulumEnv/pendulum/dtheta] Shutting down.\n",
      "[INFO] [1653483905.417089]: [/PendulumEnv/pendulum/dtheta] Shutting down.\n",
      "[INFO] [1653483905.417739]: [/PendulumEnv/env/supervisor] Shutting down.\n",
      "[INFO] [1653483905.421052]: [/PendulumEnv/environment] Shutting down.\n",
      "[INFO] [1653483905.423162]: Parameters under namespace \"/PendulumEnv\" deleted.\n"
     ]
    }
   ],
   "source": [
    "import stable_baselines3 as sb3\n",
    "from eagerx.wrappers import Flatten\n",
    "\n",
    "# Initialize Environment\n",
    "env = PendulumEnv(name=\"PendulumEnv\", rate=rate, graph=graph, engine=engine)\n",
    "\n",
    "# Toggle render\n",
    "env.render(\"human\")\n",
    "\n",
    "# Stable Baselines3 expects flattened actions & observations\n",
    "# Convert observation and action space from Dict() to Box()\n",
    "env = Flatten(env)\n",
    "\n",
    "# Initialize learner\n",
    "model = sb3.SAC(\"MlpPolicy\", env, verbose=1)\n",
    "\n",
    "# Train for 1 minute (sim time)\n",
    "model.learn(total_timesteps=int(60 * rate))\n",
    "\n",
    "env.shutdown()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
